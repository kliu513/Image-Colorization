{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from PatchGan import *\n",
    "from PIL import Image\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chan = 1 # input channels\n",
    "real_chan = 2 # output channels, should be 3 if use rgb, be 2 if use lab\n",
    "shape = 128 # shape of input image of our model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ckpt_root = \"./checkpoint/\" # directory to load and save ckpt\n",
    "classes = 365 # number of classes for our classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = UNet_Classfier(in_chan, real_chan, classes).to(device)\n",
    "ckpt_path = ckpt_root + \"UNet_Gan_v4_4.pth\"\n",
    "\n",
    "loaded_state = torch.load(ckpt_path, map_location = device)\n",
    "gen.load_state_dict(loaded_state[\"gen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please provide images that its shape is larger than (128,128)\n",
    "# will return a PIL object\n",
    "def colorized_image(path):\n",
    "    # Paramaters:\n",
    "    # path: str, the path of the image\n",
    "    orig_img = Image.open(path)\n",
    "\n",
    "    if len(np.array(orig_img).shape) == 3:\n",
    "        img = np.array(orig_img.resize((shape, shape), resample = 3))\n",
    "        img = color.rgb2lab(img).transpose((2,0,1))\n",
    "        \n",
    "        original_l = color.rgb2lab(np.array(orig_img))[:,:,0,None]\n",
    "        \n",
    "    else:\n",
    "        img = np.array(orig_img.resize((shape, shape), resample = 3))[:, :, None]\n",
    "        img = np.concatenate([img, img, img], axis = 2)\n",
    "        img = color.rgb2lab(img).transpose((2,0,1))\n",
    "        \n",
    "        original = np.array(orig_img)[:,:,None]\n",
    "        original = np.concatenate([original, original, original], axis = 2)\n",
    "        original_l = color.rgb2lab(original)[:,:,0,None]\n",
    "        \n",
    "    l = img[0,:,:][None, None, :, :]    \n",
    "    _, predicted_ab = gen(torch.tensor(l).float())\n",
    "    predicted_ab = predicted_ab.detach().cpu().numpy()[0]\n",
    "    lab = np.concatenate([l[0], predicted_ab], axis = 0).transpose((1,2,0))\n",
    "    rgb = (color.lab2rgb(lab) * 255).astype(\"uint8\")\n",
    "    \n",
    "    rescaled_img = Image.fromarray(rgb).resize(orig_img.size, 3)\n",
    "    rescaled_ab = color.rgb2lab(np.array(rescaled_img))[:,:,1:]\n",
    "    rescaled_rgb = color.lab2rgb(np.concatenate([original_l, rescaled_ab], axis = 2))\n",
    "    \n",
    "    return Image.fromarray((rescaled_rgb*255).astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './Evaluation/14_i.png'\n",
    "colorized_image(img_path).save('./Evaluation/14_i_p.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
